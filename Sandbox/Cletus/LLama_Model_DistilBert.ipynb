{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA RTX 5000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.device_count())  # Should return the number of GPUs\n",
    "print(torch.cuda.get_device_name(0))  # Should show the GPU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import logging\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import shutil \n",
    "\n",
    "import evaluate\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path=\"../../.env\") # path is relative to this script, adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face token set successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4077ef318074482aac2aa993ebb4935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095fd3eac84a4e79808a2c7aa05208c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting huggingface token\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n",
    "print(\"Hugging Face token set successfully.\")\n",
    "os.environ[\"HF_HOME\"] = \"D:/huggingface_cache\" \n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"D:/huggingface_cache\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = \"D:/huggingface_cache\"\n",
    "logging.info(f\"Setting up Hugging Face environment variables...\")\n",
    "\n",
    "logging.info(f\"HF_HOME: {os.getenv('HF_HOME')}\")\n",
    "logging.info(f\"TRANSFORMERS_CACHE: {os.getenv('TRANSFORMERS_CACHE')}\")\n",
    "logging.info(f\"HUGGINGFACE_HUB_CACHE: {os.getenv('HUGGINGFACE_HUB_CACHE')}\")\n",
    "\n",
    "transformers.utils.hub.TRANSFORMERS_CACHE = \"D:/huggingface_cache\"\n",
    "\n",
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Set pad token to eos token if not set\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd072fe89a14691936e2fc911d4ca5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bc4a09af8d40cda2ca70a3ecdb81dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test chunk\n",
    "chunk = '''\n",
    "Chapter 1: Introduction\n",
    "Chapter 2: Photosynthesis and Plant Growth\n",
    "\n",
    "Photosynthesis is the process by which green plants convert sunlight into energy. This energy is essential for plant growth and food production. The process takes place in the chloroplasts of plant cells, where sunlight, carbon dioxide, and water are converted into glucose and oxygen.\n",
    "\n",
    "Section 5.1: Economic Impacts of Climate Change\n",
    "\n",
    "Recent studies have shown that rising global temperatures and extreme weather events can significantly affect agricultural yields, infrastructure stability, and overall economic productivity in both developed and developing nations.\n",
    "\n",
    "Table of Contents\n",
    "\n",
    "Preface ............................................. v  \n",
    "Chapter 1: Introduction ............................. 1  \n",
    "Chapter 2: Background ............................... 5  \n",
    "Chapter 3: Methodology .............................. 12  \n",
    "References ......................................... 45\n",
    "\n",
    "References\n",
    "\n",
    "1. Smith, J. (2021). Introduction to Biology. Academic Press.  \n",
    "2. Jones, M. & Lee, K. (2020). Climate Science: A Global Perspective. Springer.  \n",
    "3. WHO Report on Air Quality, 2019.\n",
    "\n",
    "Preface\n",
    "\n",
    "This book provides an overview of key topics in environmental science. The reader is encouraged to explore the chapters in sequence, but each chapter can also be read independently based on interest.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(chunk, questions_num):\n",
    "    return f\"\"\"\n",
    "You are a question generation model. Only generate questions if the text segment below contains useful, topic-relevant content. Ignore and do not generate questions for sections like prefaces, indexes, tables of contents, references, or bibliographies.\n",
    "\n",
    "If the chunk is not useful, return the string: \"This chunk is not useful.\"\n",
    "\n",
    "Otherwise, generate {questions_num} question-answer pairs based on the following text segment. \n",
    "Return the result in valid JSON format as a list of objects.\n",
    "\n",
    "Text Segment:\n",
    "\n",
    "{chunk}\n",
    "\n",
    "Response Format:\n",
    "[\n",
    "    {{\"question\": \"generated question\", \"answer\": \"generated answer\"}},\n",
    "]\n",
    "\n",
    "Each answer should be at least 250 words long.\n",
    "\n",
    "Do NOT include any explanation or preamble before or after the JSON output.\n",
    "Return ONLY valid JSON output or the string: \"This chunk is not useful.\"\n",
    "\n",
    "Answer:\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk Being Tested ---\n",
      "\n",
      "\n",
      "Chapter 1: Introduction\n",
      "Chapter 2: Photosynthesis and Plant Growth\n",
      "\n",
      "Photosynthesis is the process by which green plants convert sunlight into energy. This energy is essential for plant growth and food production. The process takes place in the chloroplasts of plant cells, where sunlight, carbon dioxide, and water are converted into glucose and oxygen.\n",
      "\n",
      "Section 5.1: Economic Impacts of Climate Change\n",
      "\n",
      "Recent studies have shown that rising global temperatures and extreme weather events can significantly affect agricultural yields, infrastructure stability, and overall economic productivity in both developed and developing nations.\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "Preface ............................................. v  \n",
      "Chapter 1: Introduction ............................. 1  \n",
      "Chapter 2: Background ............................... 5  \n",
      "Chapter 3: Methodology .............................. 12  \n",
      "References ......................................... 45\n",
      "\n",
      "References\n",
      "\n",
      "1. Smith, J. (2021). Introduction to Biology. Academic Press.  \n",
      "2. Jones, M. & Lee, K. (2020). Climate Science: A Global Perspective. Springer.  \n",
      "3. WHO Report on Air Quality, 2019.\n",
      "\n",
      "Preface\n",
      "\n",
      "This book provides an overview of key topics in environmental science. The reader is encouraged to explore the chapters in sequence, but each chapter can also be read independently based on interest.\n",
      "\n",
      "\n",
      "\n",
      "--- Model Output ---\n",
      "\n",
      "{\n",
      "        \"question\": \"How does photosynthesis affect plant growth?\",\n",
      "        \"answer\": \"Photosynthesis is the process by which green plants convert sunlight into energy. This energy is essential for plant growth and food production. The process takes place in the chloroplasts of plant cells, where sunlight, carbon dioxide, and water are converted into glucose and oxygen. Glucose is a simple sugar that provides energy for the plant, while oxygen is a byproduct of the process that is released into the atmosphere. The energy produced by photosynthesis is used by the plant for growth, reproduction, and other metabolic processes.\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What are the economic impacts of climate change?\",\n",
      "        \"answer\": \"Recent studies have shown that rising global temperatures and extreme weather events can significantly affect agricultural yields, infrastructure stability, and overall economic productivity in both developed and developing nations. For example, a 2019 study by the World Bank estimated that climate change could reduce global GDP by 7% by 2050. Additionally, a 2020 report by the Intergovernmental Panel on Climate Change (IPCC) found that climate change could lead to the loss of 1.2 million jobs in the agriculture sector by 2050. These economic impacts can\n",
      "\n",
      "⚠️ JSON parse error: Extra data: line 4 column 6 (char 640). Model likely did not follow prompt instructions.\n"
     ]
    }
   ],
   "source": [
    "#  prompt with filtering instruction\n",
    "prompt = build_prompt(chunk, 2)\n",
    "\n",
    "# Send to model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "try:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output_tokens = model.generate(**inputs, max_new_tokens=256, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    generated_tokens = output_tokens[0][len(inputs[\"input_ids\"][0]):]\n",
    "    generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "\n",
    "    print(\"\\n--- Chunk Being Tested ---\\n\")\n",
    "    print(chunk)\n",
    "\n",
    "    print(\"\\n--- Model Output ---\\n\")\n",
    "    print(generated_text)\n",
    "\n",
    "    if generated_text == \"This chunk is not useful.\":\n",
    "        print(\"\\n✅ The model skipped this chunk because it identified it as non-useful content (e.g., references, preface, etc.).\")\n",
    "    else:\n",
    "        try:\n",
    "            qa_pairs = json.loads(generated_text)\n",
    "            if isinstance(qa_pairs, list):\n",
    "                print(f\"\\n⚠️ The model generated {len(qa_pairs)} question-answer pairs. It may not have correctly skipped this chunk.\")\n",
    "            else:\n",
    "                print(\"\\n⚠️ JSON output is not a list. Model may not have followed instructions.\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️ JSON parse error: {e}. Model likely did not follow prompt instructions.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Model generation error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-forge-Copy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
