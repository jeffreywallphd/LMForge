{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Based on Chunk Size using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 128-size chunks (overlap: 19) from Documents/Legal Aspects of Corporate Management and Finance.pdf...\n",
      "Extracting 128-size chunks (overlap: 19) from Documents/PrinciplesofFinance-WEB.pdf...\n",
      "Extracting 128-size chunks (overlap: 19) from Documents/Financial-Management-for-Small-Businesses-2nd-OER-Edition-1627674276.pdf...\n",
      "Extracting 128-size chunks (overlap: 19) from Documents/International Finance - Theory and Policy.pdf...\n",
      "Extraction complete. Data saved to Results/extracted_chunk_128_overlap.json\n"
     ]
    }
   ],
   "source": [
    "import fitz  \n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def extract_chunks_langchain(pdf_path, chunk_size_words, overlap_words):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\".join(page.get_text(\"text\") for page in doc)\n",
    "\n",
    "    # Estimate characters per word if you want word-based approximation\n",
    "    avg_chars_per_word = 5  \n",
    "    chunk_size = chunk_size_words * avg_chars_per_word\n",
    "    overlap = overlap_words * avg_chars_per_word\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    return splitter.split_text(full_text)\n",
    "    \n",
    "\n",
    "pdf_files = [\n",
    "    \"Documents/Legal Aspects of Corporate Management and Finance.pdf\",\n",
    "    \"Documents/PrinciplesofFinance-WEB.pdf\",\n",
    "    \"Documents/Financial-Management-for-Small-Businesses-2nd-OER-Edition-1627674276.pdf\",\n",
    "    \"Documents/International Finance - Theory and Policy.pdf\",\n",
    "]\n",
    "\n",
    "chunk_sizes = [128]\n",
    "overlap_ratio = 0.15  \n",
    "\n",
    "overlap = int(128 * overlap_ratio) \n",
    "output_data = {}\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    if os.path.exists(pdf_file):\n",
    "        print(f\"Extracting {128}-size chunks (overlap: {overlap}) from {pdf_file}...\")\n",
    "        chunks = extract_chunks_langchain(pdf_file, 128, overlap)\n",
    "        output_data[pdf_file] = chunks\n",
    "    else:\n",
    "        print(f\"File not found: {pdf_file}\")\n",
    "\n",
    "os.makedirs(\"Results\", exist_ok=True)\n",
    "output_filename = f\"Results/extracted_chunk_{128}_overlap.json\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(output_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Extraction complete. Data saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling dataset saved to Results/chunks_for_labeling_128.jsonl\n"
     ]
    }
   ],
   "source": [
    "labeling_output = f\"Results/chunks_for_labeling.jsonl\"\n",
    "\n",
    "with open(labeling_output, \"w\", encoding=\"utf-8\") as f:\n",
    "    for pdf_file, chunks in output_data.items():\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            record = {\n",
    "                \"pdf_file\": pdf_file,\n",
    "                \"chunk_id\": f\"{os.path.basename(pdf_file)}_chunk_{idx}\",\n",
    "                \"text\": chunk,\n",
    "                \"label\": None  # To be filled during manual labeling\n",
    "            }\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Labeling dataset saved to {labeling_output}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n",
      "Loaded 1254 labeled chunks\n",
      "Label distribution: Counter({1: 1117, 0: 137})\n",
      "Warning: The dataset is imbalanced. Consider balancing it before training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad92943ba274471ac58d3f818cfef0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8d22cd35c24527b7b8ce1649c93b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/251 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [378/378 00:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.09059876948595047, 'eval_runtime': 0.9197, 'eval_samples_per_second': 272.925, 'eval_steps_per_second': 34.795, 'epoch': 3.0}\n",
      "Model and tokenizer saved to ./chunk_classifier_distilbert\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import transformers\n",
    "print(transformers.__version__)\n",
    "\n",
    "\n",
    "# loading labeled chunks\n",
    "data = []\n",
    "with open(\"Results/labeled_chunks.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        if record[\"label\"] is not None:\n",
    "            data.append({\"text\": record[\"text\"], \"label\": int(record[\"label\"])})\n",
    "\n",
    "print(f\"Loaded {len(data)} labeled chunks\")\n",
    "\n",
    "# Ensure labels are integers\n",
    "for record in data:\n",
    "    if isinstance(record[\"label\"], str):\n",
    "        record[\"label\"] = int(record[\"label\"])  \n",
    "\n",
    "# Ensure text is a string\n",
    "for record in data:\n",
    "    if not isinstance(record[\"text\"], str):\n",
    "        record[\"text\"] = str(record[\"text\"])  # Convert to string if not already\n",
    "\n",
    "# class distribution\n",
    "from collections import Counter\n",
    "label_counts = Counter(record[\"label\"] for record in data)\n",
    "print(\"Label distribution:\", label_counts)\n",
    "\n",
    "# Label distribution: Counter({1: 1117, 0: 137})\n",
    "# Ensure the dataset is balanced\n",
    "if label_counts[0] < label_counts[1]:\n",
    "    print(\"Warning: The dataset is imbalanced. Consider balancing it before training.\")\n",
    "\n",
    "\n",
    "\n",
    "# Train-test split with balanced classes\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, stratify=[record[\"label\"] for record in data], random_state=42)\n",
    "\n",
    "# Loading dataset\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "# Loading tokenizer and model (DistilBERT)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Remove text field for training\n",
    "train_dataset = train_dataset.remove_columns([\"text\"])\n",
    "test_dataset = test_dataset.remove_columns([\"text\"])\n",
    "\n",
    "# Load model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./chunk_classifier_distilbert_results\",\n",
    "   # evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Training\n",
    "trainer.train()\n",
    "\n",
    "# Evaluating\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", eval_results)\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(\"./chunk_classifier_distilbert\")\n",
    "tokenizer.save_pretrained(\"./chunk_classifier_distilbert\")\n",
    "\n",
    "print(\"Model and tokenizer saved to ./chunk_classifier_distilbert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your fine-tuned model and tokenizer\n",
    "model_path = \"./chunk_classifier_distilbert\"\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()  # set to evaluation mode\n",
    "\n",
    "# Send to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_chunk(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"Content\" if prediction == 1 else \"Non-content\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: Content\n",
      "Example 2: Content\n"
     ]
    }
   ],
   "source": [
    "example_1 = \"\"\"**Table of Contents**\n",
    "\n",
    "Introduction.................................................... 1\n",
    "    1.1 Background............................................ 3\n",
    "    1.2 Objectives............................................ 5\n",
    "Chapter 1: Methodology......................................... 1\"\"\"\n",
    "example_2 = \"By default: Evaluation happens only at the end of training You won’t see eval loss after each epoch, but training still works fine If you want evaluation during training and evaluation_strategy still breaks, let me know — I can show how to manually call trainer.evaluate() after each epoch.\"\n",
    "print(\"Example 1:\", classify_chunk(example_1))\n",
    "print(\"Example 2:\", classify_chunk(example_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
